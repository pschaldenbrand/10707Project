{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data_x = np.load('data_x_scipy.npy')\n",
    "# data_y = np.load('data_y_scipy.npy')\n",
    "\n",
    "data_x = np.load('data_x_mel_spectro.npy')\n",
    "data_y = np.load('data_y_mel_spectro.npy')\n",
    "\n",
    "data_x = np.transpose(data_x, (0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.01, random_state=0)\n",
    "\n",
    "del data_x, data_y\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Flatten,\\\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,GlobalAveragePooling2D, GlobalMaxPooling2D, Add, \\\n",
    "    AveragePooling2D, Reshape, LSTM, TimeDistributed, Activation, ConvLSTM2D, MaxPooling3D\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Time distributed dense layer into an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_7 (TimeDist (None, 1200, 20)          2580      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1200, 20)          0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 1200, 20)          3280      \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 192008    \n",
      "=================================================================\n",
      "Total params: 197,868\n",
      "Trainable params: 197,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Dense(20, activation='tanh'), \n",
    "                          input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(hidden_size, return_sequences=True, activation='tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6330 samples, validate on 1583 samples\n",
      "Epoch 1/100\n",
      "6330/6330 [==============================] - 247s 39ms/step - loss: 1.9639 - acc: 0.2670 - val_loss: 1.8939 - val_acc: 0.3095\n",
      "Epoch 2/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 1.7844 - acc: 0.3348 - val_loss: 1.8218 - val_acc: 0.3506\n",
      "Epoch 3/100\n",
      "6330/6330 [==============================] - 224s 35ms/step - loss: 1.7272 - acc: 0.3629 - val_loss: 1.8211 - val_acc: 0.3316\n",
      "Epoch 4/100\n",
      "6330/6330 [==============================] - 223s 35ms/step - loss: 1.6834 - acc: 0.3784 - val_loss: 1.8204 - val_acc: 0.3323\n",
      "Epoch 5/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 1.6502 - acc: 0.3997 - val_loss: 1.7905 - val_acc: 0.3544\n",
      "Epoch 6/100\n",
      "6330/6330 [==============================] - 221s 35ms/step - loss: 1.5988 - acc: 0.4197 - val_loss: 1.7912 - val_acc: 0.3594\n",
      "Epoch 7/100\n",
      "6330/6330 [==============================] - 223s 35ms/step - loss: 1.5525 - acc: 0.4425 - val_loss: 1.8768 - val_acc: 0.3291\n",
      "Epoch 8/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 1.5100 - acc: 0.4577 - val_loss: 1.8130 - val_acc: 0.3373\n",
      "Epoch 9/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 1.4750 - acc: 0.4720 - val_loss: 1.8956 - val_acc: 0.3399\n",
      "Epoch 10/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 1.4510 - acc: 0.4867 - val_loss: 1.8460 - val_acc: 0.3670\n",
      "Epoch 11/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 1.4338 - acc: 0.4891 - val_loss: 1.8613 - val_acc: 0.3437\n",
      "Epoch 12/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 1.3592 - acc: 0.5100 - val_loss: 1.8315 - val_acc: 0.3714\n",
      "Epoch 13/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 1.3505 - acc: 0.5256 - val_loss: 1.9314 - val_acc: 0.3626\n",
      "Epoch 14/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 1.3019 - acc: 0.5390 - val_loss: 1.9356 - val_acc: 0.3329\n",
      "Epoch 15/100\n",
      "6330/6330 [==============================] - 230s 36ms/step - loss: 1.3072 - acc: 0.5417 - val_loss: 1.9326 - val_acc: 0.3335\n",
      "Epoch 16/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 1.2549 - acc: 0.5547 - val_loss: 1.9361 - val_acc: 0.3443\n",
      "Epoch 17/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 1.2283 - acc: 0.5690 - val_loss: 2.0154 - val_acc: 0.3405\n",
      "Epoch 18/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 1.2266 - acc: 0.5665 - val_loss: 1.9902 - val_acc: 0.3493\n",
      "Epoch 19/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 1.1590 - acc: 0.5912 - val_loss: 1.9816 - val_acc: 0.3443\n",
      "Epoch 20/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 1.1439 - acc: 0.5918 - val_loss: 2.1169 - val_acc: 0.3260\n",
      "Epoch 21/100\n",
      "6330/6330 [==============================] - 230s 36ms/step - loss: 1.1441 - acc: 0.5929 - val_loss: 2.0426 - val_acc: 0.3582\n",
      "Epoch 22/100\n",
      "6330/6330 [==============================] - 230s 36ms/step - loss: 1.1276 - acc: 0.6033 - val_loss: 2.0271 - val_acc: 0.3601\n",
      "Epoch 23/100\n",
      "6330/6330 [==============================] - 236s 37ms/step - loss: 1.0961 - acc: 0.6092 - val_loss: 2.1751 - val_acc: 0.3354\n",
      "Epoch 24/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 1.0684 - acc: 0.6264 - val_loss: 2.1025 - val_acc: 0.3361\n",
      "Epoch 25/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 1.0468 - acc: 0.6253 - val_loss: 2.1406 - val_acc: 0.3424\n",
      "Epoch 26/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 1.0020 - acc: 0.6458 - val_loss: 2.1513 - val_acc: 0.3449\n",
      "Epoch 27/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 1.0239 - acc: 0.6359 - val_loss: 2.1744 - val_acc: 0.3506\n",
      "Epoch 28/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.9992 - acc: 0.6494 - val_loss: 2.1941 - val_acc: 0.3190\n",
      "Epoch 29/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.9902 - acc: 0.6499 - val_loss: 2.2935 - val_acc: 0.3114\n",
      "Epoch 30/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.9558 - acc: 0.6616 - val_loss: 2.2054 - val_acc: 0.3367\n",
      "Epoch 31/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.9482 - acc: 0.6675 - val_loss: 2.2124 - val_acc: 0.3354\n",
      "Epoch 32/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.9554 - acc: 0.6619 - val_loss: 2.2223 - val_acc: 0.3424\n",
      "Epoch 33/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.8932 - acc: 0.6870 - val_loss: 2.3259 - val_acc: 0.3449\n",
      "Epoch 34/100\n",
      "6330/6330 [==============================] - 232s 37ms/step - loss: 0.9066 - acc: 0.6845 - val_loss: 2.2439 - val_acc: 0.3323\n",
      "Epoch 35/100\n",
      "6330/6330 [==============================] - 233s 37ms/step - loss: 0.9164 - acc: 0.6731 - val_loss: 2.3330 - val_acc: 0.3481\n",
      "Epoch 36/100\n",
      "6330/6330 [==============================] - 232s 37ms/step - loss: 0.8769 - acc: 0.6929 - val_loss: 2.3719 - val_acc: 0.3316\n",
      "Epoch 37/100\n",
      "6330/6330 [==============================] - 231s 36ms/step - loss: 0.8721 - acc: 0.6900 - val_loss: 2.3636 - val_acc: 0.3411\n",
      "Epoch 38/100\n",
      "6330/6330 [==============================] - 235s 37ms/step - loss: 0.8622 - acc: 0.6886 - val_loss: 2.3926 - val_acc: 0.3260\n",
      "Epoch 39/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 0.8633 - acc: 0.6937 - val_loss: 2.4246 - val_acc: 0.3361\n",
      "Epoch 40/100\n",
      "6330/6330 [==============================] - 235s 37ms/step - loss: 0.8770 - acc: 0.6866 - val_loss: 2.4617 - val_acc: 0.2982\n",
      "Epoch 41/100\n",
      "6330/6330 [==============================] - 237s 37ms/step - loss: 0.8643 - acc: 0.6945 - val_loss: 2.3483 - val_acc: 0.3424\n",
      "Epoch 42/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 0.7945 - acc: 0.7180 - val_loss: 2.4724 - val_acc: 0.3316\n",
      "Epoch 43/100\n",
      "6330/6330 [==============================] - 224s 35ms/step - loss: 0.8100 - acc: 0.7112 - val_loss: 2.4437 - val_acc: 0.3449\n",
      "Epoch 44/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7954 - acc: 0.7186 - val_loss: 2.4424 - val_acc: 0.3253\n",
      "Epoch 45/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.7978 - acc: 0.7193 - val_loss: 2.5295 - val_acc: 0.3323\n",
      "Epoch 46/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 0.7919 - acc: 0.7194 - val_loss: 2.4301 - val_acc: 0.3316\n",
      "Epoch 47/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7768 - acc: 0.7209 - val_loss: 2.4869 - val_acc: 0.3285\n",
      "Epoch 48/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7591 - acc: 0.7329 - val_loss: 2.4728 - val_acc: 0.3146\n",
      "Epoch 49/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7571 - acc: 0.7379 - val_loss: 2.5470 - val_acc: 0.3437\n",
      "Epoch 50/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 0.7577 - acc: 0.7306 - val_loss: 2.5307 - val_acc: 0.3335\n",
      "Epoch 51/100\n",
      "6330/6330 [==============================] - 225s 35ms/step - loss: 0.7402 - acc: 0.7412 - val_loss: 2.5319 - val_acc: 0.3538\n",
      "Epoch 52/100\n",
      "6330/6330 [==============================] - 231s 37ms/step - loss: 0.7521 - acc: 0.7330 - val_loss: 2.5484 - val_acc: 0.3253\n",
      "Epoch 53/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7330 - acc: 0.7427 - val_loss: 2.5303 - val_acc: 0.3304\n",
      "Epoch 54/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7121 - acc: 0.7439 - val_loss: 2.5773 - val_acc: 0.3266\n",
      "Epoch 55/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.7005 - acc: 0.7566 - val_loss: 2.7138 - val_acc: 0.3316\n",
      "Epoch 56/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.7416 - acc: 0.7385 - val_loss: 2.7657 - val_acc: 0.3298\n",
      "Epoch 57/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.7115 - acc: 0.7502 - val_loss: 2.6549 - val_acc: 0.3474\n",
      "Epoch 58/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.7100 - acc: 0.7504 - val_loss: 2.6750 - val_acc: 0.3291\n",
      "Epoch 59/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 0.6844 - acc: 0.7583 - val_loss: 2.6135 - val_acc: 0.3178\n",
      "Epoch 60/100\n",
      "6330/6330 [==============================] - 224s 35ms/step - loss: 0.6949 - acc: 0.7553 - val_loss: 2.6535 - val_acc: 0.3316\n",
      "Epoch 61/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 0.7024 - acc: 0.7518 - val_loss: 2.6759 - val_acc: 0.3323\n",
      "Epoch 62/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.6791 - acc: 0.7578 - val_loss: 2.6411 - val_acc: 0.3291\n",
      "Epoch 63/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.6866 - acc: 0.7588 - val_loss: 2.6268 - val_acc: 0.3481\n",
      "Epoch 64/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.6864 - acc: 0.7635 - val_loss: 2.7154 - val_acc: 0.3253\n",
      "Epoch 65/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.6550 - acc: 0.7714 - val_loss: 2.6314 - val_acc: 0.3159\n",
      "Epoch 66/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6784 - acc: 0.7570 - val_loss: 2.6586 - val_acc: 0.3437\n",
      "Epoch 67/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6653 - acc: 0.7654 - val_loss: 2.6289 - val_acc: 0.3392\n",
      "Epoch 68/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.6527 - acc: 0.7728 - val_loss: 2.6682 - val_acc: 0.3260\n",
      "Epoch 69/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6522 - acc: 0.7687 - val_loss: 2.7296 - val_acc: 0.3361\n",
      "Epoch 70/100\n",
      "6330/6330 [==============================] - 225s 36ms/step - loss: 0.6436 - acc: 0.7681 - val_loss: 2.7660 - val_acc: 0.3298\n",
      "Epoch 71/100\n",
      "6330/6330 [==============================] - 226s 36ms/step - loss: 0.6394 - acc: 0.7744 - val_loss: 2.6991 - val_acc: 0.3266\n",
      "Epoch 72/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 0.6264 - acc: 0.7790 - val_loss: 2.7576 - val_acc: 0.3424\n",
      "Epoch 73/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6134 - acc: 0.7803 - val_loss: 2.7390 - val_acc: 0.3335\n",
      "Epoch 74/100\n",
      "6330/6330 [==============================] - 231s 36ms/step - loss: 0.6247 - acc: 0.7791 - val_loss: 2.7421 - val_acc: 0.3348\n",
      "Epoch 75/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6071 - acc: 0.7864 - val_loss: 2.7787 - val_acc: 0.3354\n",
      "Epoch 76/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6118 - acc: 0.7856 - val_loss: 2.9374 - val_acc: 0.3247\n",
      "Epoch 77/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.6310 - acc: 0.7787 - val_loss: 2.7852 - val_acc: 0.3335\n",
      "Epoch 78/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6196 - acc: 0.7852 - val_loss: 2.7866 - val_acc: 0.3260\n",
      "Epoch 79/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6191 - acc: 0.7853 - val_loss: 2.7874 - val_acc: 0.3203\n",
      "Epoch 80/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6114 - acc: 0.7795 - val_loss: 2.8527 - val_acc: 0.3405\n",
      "Epoch 81/100\n",
      "6330/6330 [==============================] - 230s 36ms/step - loss: 0.6027 - acc: 0.7889 - val_loss: 2.7621 - val_acc: 0.3253\n",
      "Epoch 82/100\n",
      "6330/6330 [==============================] - 231s 36ms/step - loss: 0.5912 - acc: 0.7910 - val_loss: 2.8071 - val_acc: 0.3386\n",
      "Epoch 83/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.5775 - acc: 0.7961 - val_loss: 2.8025 - val_acc: 0.3329\n",
      "Epoch 84/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 0.6347 - acc: 0.7725 - val_loss: 2.8126 - val_acc: 0.3266\n",
      "Epoch 85/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.6071 - acc: 0.7763 - val_loss: 2.8146 - val_acc: 0.3380\n",
      "Epoch 86/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6042 - acc: 0.7899 - val_loss: 2.8394 - val_acc: 0.3253\n",
      "Epoch 87/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.6206 - acc: 0.7847 - val_loss: 2.9753 - val_acc: 0.3316\n",
      "Epoch 88/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.5942 - acc: 0.7897 - val_loss: 2.9647 - val_acc: 0.3190\n",
      "Epoch 89/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.5867 - acc: 0.7877 - val_loss: 2.7952 - val_acc: 0.3373\n",
      "Epoch 90/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 0.5770 - acc: 0.8003 - val_loss: 2.8512 - val_acc: 0.3291\n",
      "Epoch 91/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.5514 - acc: 0.8028 - val_loss: 2.8927 - val_acc: 0.3228\n",
      "Epoch 92/100\n",
      "6330/6330 [==============================] - 229s 36ms/step - loss: 0.5648 - acc: 0.7995 - val_loss: 2.9259 - val_acc: 0.3253\n",
      "Epoch 93/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.5730 - acc: 0.7978 - val_loss: 2.9655 - val_acc: 0.3234\n",
      "Epoch 94/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.5605 - acc: 0.8071 - val_loss: 2.9790 - val_acc: 0.3121\n",
      "Epoch 95/100\n",
      "6330/6330 [==============================] - 230s 36ms/step - loss: 0.5487 - acc: 0.8103 - val_loss: 2.8758 - val_acc: 0.3279\n",
      "Epoch 96/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.5505 - acc: 0.8101 - val_loss: 2.9634 - val_acc: 0.3291\n",
      "Epoch 97/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.5397 - acc: 0.8161 - val_loss: 2.8771 - val_acc: 0.3316\n",
      "Epoch 98/100\n",
      "6330/6330 [==============================] - 233s 37ms/step - loss: 0.5555 - acc: 0.8033 - val_loss: 2.9972 - val_acc: 0.3316\n",
      "Epoch 99/100\n",
      "6330/6330 [==============================] - 228s 36ms/step - loss: 0.5685 - acc: 0.7976 - val_loss: 3.0065 - val_acc: 0.3260\n",
      "Epoch 100/100\n",
      "6330/6330 [==============================] - 227s 36ms/step - loss: 0.5696 - acc: 0.7973 - val_loss: 3.0119 - val_acc: 0.3190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x281045a1240>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 64\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "                       validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two 1D Convolution layers into an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=40, kernel_size=3, strides=1, activation=\"tanh\", input_shape=(1200, 128..., padding=\"same\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 1200, 40)          15400     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 600, 40)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 598, 40)           4840      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 598, 40)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 598, 20)           4880      \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 11960)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 11960)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 95688     \n",
      "=================================================================\n",
      "Total params: 120,808\n",
      "Trainable params: 120,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=40, kernel_size=3, strides=1,\n",
    "                activation='tanh', border_mode='same',\n",
    "                input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=40, kernel_size=3, strides=1,\n",
    "                activation='tanh'))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(20, activation='tanh'), \n",
    "#                           input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(hidden_size, return_sequences=True, activation='tanh'))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(50, activation='tanh')))\n",
    "# model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6330 samples, validate on 1583 samples\n",
      "Epoch 1/100\n",
      "6330/6330 [==============================] - 156s 25ms/step - loss: 1.9516 - acc: 0.2431 - val_loss: 1.8256 - val_acc: 0.3140\n",
      "Epoch 2/100\n",
      "6330/6330 [==============================] - 162s 26ms/step - loss: 1.8026 - acc: 0.3191 - val_loss: 1.7955 - val_acc: 0.3203\n",
      "Epoch 3/100\n",
      "6330/6330 [==============================] - 150s 24ms/step - loss: 1.7628 - acc: 0.3400 - val_loss: 1.7553 - val_acc: 0.3405\n",
      "Epoch 4/100\n",
      "6330/6330 [==============================] - 151s 24ms/step - loss: 1.7010 - acc: 0.3657 - val_loss: 1.7758 - val_acc: 0.3367\n",
      "Epoch 5/100\n",
      "6330/6330 [==============================] - 150s 24ms/step - loss: 1.6817 - acc: 0.3722 - val_loss: 1.8449 - val_acc: 0.3481\n",
      "Epoch 6/100\n",
      "6330/6330 [==============================] - 150s 24ms/step - loss: 1.6592 - acc: 0.3877 - val_loss: 1.8076 - val_acc: 0.3380\n",
      "Epoch 7/100\n",
      "6330/6330 [==============================] - 155s 24ms/step - loss: 1.6603 - acc: 0.3826 - val_loss: 1.7596 - val_acc: 0.3582\n",
      "Epoch 8/100\n",
      "6330/6330 [==============================] - 153s 24ms/step - loss: 1.6548 - acc: 0.3926 - val_loss: 1.7234 - val_acc: 0.3771\n",
      "Epoch 9/100\n",
      "6330/6330 [==============================] - 147s 23ms/step - loss: 1.6083 - acc: 0.4115 - val_loss: 1.8004 - val_acc: 0.3411\n",
      "Epoch 10/100\n",
      "6330/6330 [==============================] - 140s 22ms/step - loss: 1.5608 - acc: 0.4267 - val_loss: 1.7397 - val_acc: 0.3557\n",
      "Epoch 11/100\n",
      "6330/6330 [==============================] - 141s 22ms/step - loss: 1.5860 - acc: 0.4194 - val_loss: 1.7285 - val_acc: 0.3714\n",
      "Epoch 12/100\n",
      "6330/6330 [==============================] - 146s 23ms/step - loss: 1.5232 - acc: 0.4477 - val_loss: 1.6945 - val_acc: 0.3866\n",
      "Epoch 13/100\n",
      "6330/6330 [==============================] - 144s 23ms/step - loss: 1.5132 - acc: 0.4556 - val_loss: 1.8404 - val_acc: 0.3481\n",
      "Epoch 14/100\n",
      "6330/6330 [==============================] - 143s 23ms/step - loss: 1.4853 - acc: 0.4656 - val_loss: 1.7592 - val_acc: 0.3752\n",
      "Epoch 15/100\n",
      "6330/6330 [==============================] - 141s 22ms/step - loss: 1.4491 - acc: 0.4864 - val_loss: 1.7384 - val_acc: 0.3910\n",
      "Epoch 16/100\n",
      "6330/6330 [==============================] - 134s 21ms/step - loss: 1.4395 - acc: 0.4817 - val_loss: 1.7557 - val_acc: 0.4005\n",
      "Epoch 17/100\n",
      "6330/6330 [==============================] - 145s 23ms/step - loss: 1.3942 - acc: 0.5035 - val_loss: 1.7770 - val_acc: 0.4030\n",
      "Epoch 18/100\n",
      "6330/6330 [==============================] - 151s 24ms/step - loss: 1.3750 - acc: 0.5019 - val_loss: 1.7886 - val_acc: 0.3822\n",
      "Epoch 19/100\n",
      "6330/6330 [==============================] - 149s 23ms/step - loss: 1.3515 - acc: 0.5136 - val_loss: 1.8040 - val_acc: 0.3917\n",
      "Epoch 20/100\n",
      "6330/6330 [==============================] - 142s 22ms/step - loss: 1.3050 - acc: 0.5401 - val_loss: 1.8780 - val_acc: 0.3677\n",
      "Epoch 21/100\n",
      "6330/6330 [==============================] - 155s 25ms/step - loss: 1.2858 - acc: 0.5461 - val_loss: 1.7997 - val_acc: 0.3847\n",
      "Epoch 22/100\n",
      "6330/6330 [==============================] - 150s 24ms/step - loss: 1.2568 - acc: 0.5523 - val_loss: 1.8233 - val_acc: 0.3929\n",
      "Epoch 23/100\n",
      "6330/6330 [==============================] - 160s 25ms/step - loss: 1.2287 - acc: 0.5648 - val_loss: 1.9360 - val_acc: 0.3803\n",
      "Epoch 24/100\n",
      "6330/6330 [==============================] - 138s 22ms/step - loss: 1.1956 - acc: 0.5681 - val_loss: 1.8462 - val_acc: 0.3872\n",
      "Epoch 25/100\n",
      "6330/6330 [==============================] - 146s 23ms/step - loss: 1.1738 - acc: 0.5776 - val_loss: 2.0162 - val_acc: 0.3512\n",
      "Epoch 26/100\n",
      "6330/6330 [==============================] - 146s 23ms/step - loss: 1.1720 - acc: 0.5814 - val_loss: 1.9228 - val_acc: 0.3708\n",
      "Epoch 27/100\n",
      "2816/6330 [============>.................] - ETA: 1:08 - loss: 1.1601 - acc: 0.5877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b69d19008340>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n\u001b[1;32m----> 4\u001b[1;33m                        validation_data=(x_val,y_val))\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 64\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "                       validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 1200, 20)          11920     \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 192008    \n",
      "=================================================================\n",
      "Total params: 203,928\n",
      "Trainable params: 203,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(filters=40, kernel_size=3, strides=1,\n",
    "#                 activation='tanh', border_mode='same',\n",
    "#                 input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(filters=40, kernel_size=3, strides=1,\n",
    "#                 activation='tanh'))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(20, activation='tanh'), \n",
    "#                           input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(hidden_size, return_sequences=True, activation='tanh', \n",
    "              input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(50, activation='tanh')))\n",
    "# model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6330 samples, validate on 1583 samples\n",
      "Epoch 1/60\n",
      "6330/6330 [==============================] - 251s 40ms/step - loss: 2.0006 - acc: 0.2706 - val_loss: 1.8104 - val_acc: 0.3342\n",
      "Epoch 2/60\n",
      "6330/6330 [==============================] - 254s 40ms/step - loss: 1.7532 - acc: 0.3512 - val_loss: 1.8216 - val_acc: 0.3203\n",
      "Epoch 3/60\n",
      "6330/6330 [==============================] - 246s 39ms/step - loss: 1.6790 - acc: 0.3853 - val_loss: 1.8981 - val_acc: 0.3102\n",
      "Epoch 4/60\n",
      "6330/6330 [==============================] - 258s 41ms/step - loss: 1.5892 - acc: 0.4269 - val_loss: 1.7859 - val_acc: 0.3474\n",
      "Epoch 5/60\n",
      "6330/6330 [==============================] - 242s 38ms/step - loss: 1.5066 - acc: 0.4668 - val_loss: 1.8761 - val_acc: 0.3228\n",
      "Epoch 6/60\n",
      "6330/6330 [==============================] - 248s 39ms/step - loss: 1.4026 - acc: 0.5073 - val_loss: 1.8621 - val_acc: 0.3190\n",
      "Epoch 7/60\n",
      " 640/6330 [==>...........................] - ETA: 3:19 - loss: 1.2785 - acc: 0.5750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-0a854ffacffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(x_train, y_train, batch_size=64, epochs=60,\n\u001b[1;32m----> 2\u001b[1;33m                        validation_data=(x_val,y_val))\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=60,\n",
    "                       validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only TIme Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_8 (TimeDist (None, 1200, 20)          2580      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1200, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 192008    \n",
      "=================================================================\n",
      "Total params: 194,588\n",
      "Trainable params: 194,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Dense(20, activation='tanh'), \n",
    "                          input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6330 samples, validate on 1583 samples\n",
      "Epoch 1/60\n",
      "6330/6330 [==============================] - 70s 11ms/step - loss: 2.1492 - acc: 0.2548 - val_loss: 1.9100 - val_acc: 0.3007\n",
      "Epoch 2/60\n",
      "6330/6330 [==============================] - 48s 8ms/step - loss: 1.8251 - acc: 0.3434 - val_loss: 1.9552 - val_acc: 0.2862\n",
      "Epoch 3/60\n",
      "6330/6330 [==============================] - 34s 5ms/step - loss: 1.7063 - acc: 0.3850 - val_loss: 1.9947 - val_acc: 0.2931\n",
      "Epoch 4/60\n",
      "6330/6330 [==============================] - 30s 5ms/step - loss: 1.5978 - acc: 0.4289 - val_loss: 2.0155 - val_acc: 0.3020\n",
      "Epoch 5/60\n",
      "6330/6330 [==============================] - 26s 4ms/step - loss: 1.5321 - acc: 0.4654 - val_loss: 2.0001 - val_acc: 0.3127\n",
      "Epoch 6/60\n",
      "6330/6330 [==============================] - 24s 4ms/step - loss: 1.4580 - acc: 0.4899 - val_loss: 2.0459 - val_acc: 0.2919\n",
      "Epoch 7/60\n",
      "6330/6330 [==============================] - 25s 4ms/step - loss: 1.4505 - acc: 0.4894 - val_loss: 2.2105 - val_acc: 0.2855\n",
      "Epoch 8/60\n",
      "6330/6330 [==============================] - 22s 3ms/step - loss: 1.3678 - acc: 0.5224 - val_loss: 2.0443 - val_acc: 0.3215\n",
      "Epoch 9/60\n",
      "6330/6330 [==============================] - 27s 4ms/step - loss: 1.3181 - acc: 0.5458 - val_loss: 2.1734 - val_acc: 0.2874\n",
      "Epoch 10/60\n",
      "6330/6330 [==============================] - 24s 4ms/step - loss: 1.3020 - acc: 0.5487 - val_loss: 2.2007 - val_acc: 0.2874\n",
      "Epoch 11/60\n",
      "4224/6330 [===================>..........] - ETA: 5s - loss: 1.2408 - acc: 0.5675"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-89247be60be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(x_train, y_train, batch_size=32, epochs=60,\n\u001b[1;32m----> 2\u001b[1;33m                        validation_data=(x_val,y_val))\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    183\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 185\u001b[1;33m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=60,\n",
    "                       validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_15 (Reshape)         (None, 1200, 128, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 1181, 128, 10)     210       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 590, 64, 10)       0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 590, 64, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 571, 64, 10)       2010      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 285, 32, 10)       0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 285, 32, 10)       0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 91200)             0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 91200)             0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 8)                 729608    \n",
      "=================================================================\n",
      "Total params: 731,828\n",
      "Trainable params: 731,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "kernel_size = (20,1)\n",
    "pool_size = (2,2)\n",
    "\n",
    "model.add(Reshape((x_train.shape[1], x_train.shape[2], 1), \n",
    "                  input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "model.add(Conv2D(filters=10, kernel_size=kernel_size, strides=1,\n",
    "                activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=10, kernel_size=kernel_size, strides=1,\n",
    "                activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6330 samples, validate on 1583 samples\n",
      "Epoch 1/20\n",
      "6330/6330 [==============================] - 92s 14ms/step - loss: 2.2308 - acc: 0.2458 - val_loss: 2.3282 - val_acc: 0.2167\n",
      "Epoch 2/20\n",
      "6330/6330 [==============================] - 76s 12ms/step - loss: 1.6476 - acc: 0.3995 - val_loss: 1.8205 - val_acc: 0.3405\n",
      "Epoch 3/20\n",
      "6330/6330 [==============================] - 63s 10ms/step - loss: 1.4756 - acc: 0.4763 - val_loss: 1.9820 - val_acc: 0.3114\n",
      "Epoch 4/20\n",
      "6330/6330 [==============================] - 65s 10ms/step - loss: 1.3294 - acc: 0.5288 - val_loss: 2.1727 - val_acc: 0.3013\n",
      "Epoch 5/20\n",
      "6330/6330 [==============================] - 64s 10ms/step - loss: 1.2017 - acc: 0.5799 - val_loss: 2.2938 - val_acc: 0.2950\n",
      "Epoch 6/20\n",
      "6330/6330 [==============================] - 64s 10ms/step - loss: 1.0880 - acc: 0.6223 - val_loss: 2.1303 - val_acc: 0.3424\n",
      "Epoch 7/20\n",
      "6330/6330 [==============================] - 62s 10ms/step - loss: 0.9698 - acc: 0.6630 - val_loss: 2.3653 - val_acc: 0.3228\n",
      "Epoch 8/20\n",
      "6330/6330 [==============================] - 59s 9ms/step - loss: 0.9307 - acc: 0.6820 - val_loss: 2.8720 - val_acc: 0.2786\n",
      "Epoch 9/20\n",
      "6330/6330 [==============================] - 66s 10ms/step - loss: 0.8246 - acc: 0.7196 - val_loss: 2.5660 - val_acc: 0.3178\n",
      "Epoch 10/20\n",
      "6330/6330 [==============================] - 64s 10ms/step - loss: 0.7757 - acc: 0.7327 - val_loss: 2.5448 - val_acc: 0.3228\n",
      "Epoch 11/20\n",
      "6330/6330 [==============================] - 71s 11ms/step - loss: 0.7390 - acc: 0.7512 - val_loss: 2.5243 - val_acc: 0.3506oss: 0.7335 - acc - ETA: 1s - loss: 0.7334 - acc\n",
      "Epoch 12/20\n",
      "6330/6330 [==============================] - 62s 10ms/step - loss: 0.7075 - acc: 0.7608 - val_loss: 2.7471 - val_acc: 0.3310\n",
      "Epoch 13/20\n",
      "6330/6330 [==============================] - 53s 8ms/step - loss: 0.6420 - acc: 0.7847 - val_loss: 2.6295 - val_acc: 0.3601\n",
      "Epoch 14/20\n",
      "6330/6330 [==============================] - 54s 9ms/step - loss: 0.6421 - acc: 0.7807 - val_loss: 3.0659 - val_acc: 0.3260\n",
      "Epoch 15/20\n",
      "6330/6330 [==============================] - 56s 9ms/step - loss: 0.5974 - acc: 0.7940 - val_loss: 2.8081 - val_acc: 0.3544\n",
      "Epoch 16/20\n",
      "6330/6330 [==============================] - 58s 9ms/step - loss: 0.5831 - acc: 0.8035 - val_loss: 2.8770 - val_acc: 0.3253\n",
      "Epoch 17/20\n",
      "6330/6330 [==============================] - 58s 9ms/step - loss: 0.5595 - acc: 0.8122 - val_loss: 2.8868 - val_acc: 0.3544\n",
      "Epoch 18/20\n",
      "6330/6330 [==============================] - 62s 10ms/step - loss: 0.5761 - acc: 0.8073 - val_loss: 2.9563 - val_acc: 0.3468\n",
      "Epoch 19/20\n",
      "6330/6330 [==============================] - 70s 11ms/step - loss: 0.5235 - acc: 0.8224 - val_loss: 3.4780 - val_acc: 0.3083\n",
      "Epoch 20/20\n",
      "6330/6330 [==============================] - 79s 13ms/step - loss: 0.4868 - acc: 0.8346 - val_loss: 3.1873 - val_acc: 0.3468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28131022438>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=16, epochs=20,\n",
    "                       validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
